{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04982cc",
   "metadata": {},
   "source": [
    "# file checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a2240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing CSV files:\n",
      "Extra CSV files:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "xml_folder = 'all_xml'\n",
    "csv_folder = 'PCNA_csv'\n",
    "\n",
    "xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n",
    "xml_basenames = [os.path.splitext(f)[0] for f in xml_files]\n",
    "\n",
    "expected_csv_files = [name + '___annotated_judgment.csv' for name in xml_basenames]\n",
    "actual_csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "missing_csv_files = [csv for csv in expected_csv_files if csv not in actual_csv_files]\n",
    "extra_csv_files = [csv for csv in actual_csv_files if csv not in expected_csv_files]\n",
    "\n",
    "print(\"Missing CSV files:\")\n",
    "for fname in missing_csv_files:\n",
    "    print(fname)\n",
    "\n",
    "print(\"Extra CSV files:\")\n",
    "for fname in extra_csv_files:\n",
    "    print(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b09ed",
   "metadata": {},
   "source": [
    "# no of premises, conclusion, support and attack edges check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee73236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'support_relations': 2272, 'attack_relations': 145, 'num_premises': 343, 'num_conclusions': 108}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "def count_xml_relations_and_types(xml_folder):\n",
    "    support_count = 0\n",
    "    attack_count = 0\n",
    "    premise_ids = set()\n",
    "    conclusion_ids = set()\n",
    "\n",
    "    for xml_file in Path(xml_folder).glob(\"*.xml\"):\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            for elem in root.iter():\n",
    "                if elem.tag == 'prem':\n",
    "                    premise_ids.add(elem.attrib.get('ID', '').strip())\n",
    "                elif elem.tag == 'conc':\n",
    "                    conclusion_ids.add(elem.attrib.get('ID', '').strip())\n",
    "\n",
    "                for rel_type in ['SUP', 'ATT']:\n",
    "                    if rel_type in elem.attrib:\n",
    "                        refs = [x.strip() for x in elem.attrib[rel_type].split('|') if x.strip()]\n",
    "                        if rel_type == 'SUP':\n",
    "                            support_count += len(refs)\n",
    "                        else:\n",
    "                            attack_count += len(refs)\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"XML parse error in {xml_file.name}: {e}\")\n",
    "\n",
    "    return {\n",
    "        'support_relations': support_count,\n",
    "        'attack_relations': attack_count,\n",
    "        'num_premises': len(premise_ids),\n",
    "        'num_conclusions': len(conclusion_ids)\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "xml_stats = count_xml_relations_and_types('all_xml_cleaned')\n",
    "print(xml_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fc4097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'support_relations': 2272, 'attack_relations': 145, 'no_relation': 8, 'unique_premises': 343, 'unique_conclusions': 108}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def count_unique_prem_conc_and_relations(csv_file):\n",
    "    premises = set()\n",
    "    conclusions = set()\n",
    "    support_count = 0\n",
    "    attack_count = 0\n",
    "    no_relation_count = 0\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            src_type = row['source_type']\n",
    "            tgt_type = row['target_type']\n",
    "            rel = row['relation']\n",
    "\n",
    "            if src_type == 'prem':\n",
    "                premises.add(row['source_ID'])\n",
    "            elif src_type == 'conc':\n",
    "                conclusions.add(row['source_ID'])\n",
    "\n",
    "            if tgt_type == 'prem':\n",
    "                premises.add(row['target_ID'])\n",
    "            elif tgt_type == 'conc':\n",
    "                conclusions.add(row['target_ID'])\n",
    "\n",
    "            if rel == 'support':\n",
    "                support_count += 1\n",
    "            elif rel == 'attack':\n",
    "                attack_count += 1\n",
    "            elif rel == 'no-relation':\n",
    "                no_relation_count += 1\n",
    "\n",
    "    return {\n",
    "        'support_relations': support_count,\n",
    "        'attack_relations': attack_count,\n",
    "        'no_relation': no_relation_count,\n",
    "        'unique_premises': len(premises),\n",
    "        'unique_conclusions': len(conclusions),\n",
    "        \n",
    "    }\n",
    "\n",
    "# Usage\n",
    "csv_file_path = 'PC_SA_including_standalone_PC.csv'\n",
    "stats = count_unique_prem_conc_and_relations(csv_file_path)\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06bfb9",
   "metadata": {},
   "source": [
    "# find missing premises and conclusions (standalone premises and conclusions which dont support/attack or get supported/attacked by any other argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "285bcada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Premises (0):\n",
      "\n",
      "Missing Conclusions (0):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "def read_xml_prem_conc_ids(xml_folder):\n",
    "    # Maps ID -> file_name for premises and conclusions\n",
    "    prem_id_to_file = {}\n",
    "    conc_id_to_file = {}\n",
    "    for xml_file in Path(xml_folder).glob('*.xml'):\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            for elem in root.iter():\n",
    "                if elem.tag == 'prem':\n",
    "                    arg_id = elem.attrib.get('ID', '').strip()\n",
    "                    if arg_id:\n",
    "                        prem_id_to_file[arg_id] = xml_file.name\n",
    "                elif elem.tag == 'conc':\n",
    "                    arg_id = elem.attrib.get('ID', '').strip()\n",
    "                    if arg_id:\n",
    "                        conc_id_to_file[arg_id] = xml_file.name\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"XML parse error in {xml_file.name}: {e}\")\n",
    "    return prem_id_to_file, conc_id_to_file\n",
    "\n",
    "def read_csv_unique_ids(csv_file):\n",
    "    # Returns sets of premise IDs and conclusion IDs found in the CSV\n",
    "    csv_prem_ids = set()\n",
    "    csv_conc_ids = set()\n",
    "    with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Add source ID to respective set\n",
    "            if row['source_type'] == 'prem' and row['source_ID']:\n",
    "                csv_prem_ids.add(row['source_ID'])\n",
    "            elif row['source_type'] == 'conc' and row['source_ID']:\n",
    "                csv_conc_ids.add(row['source_ID'])\n",
    "            # Add target ID to respective set\n",
    "            if row['target_type'] == 'prem' and row['target_ID']:\n",
    "                csv_prem_ids.add(row['target_ID'])\n",
    "            elif row['target_type'] == 'conc' and row['target_ID']:\n",
    "                csv_conc_ids.add(row['target_ID'])\n",
    "    return csv_prem_ids, csv_conc_ids\n",
    "\n",
    "def find_missing_ids(xml_folder, csv_file):\n",
    "    xml_prem_ids_map, xml_conc_ids_map = read_xml_prem_conc_ids(xml_folder)\n",
    "    csv_prem_ids, csv_conc_ids = read_csv_unique_ids(csv_file)\n",
    "    \n",
    "    missing_prem = {}\n",
    "    missing_conc = {}\n",
    "\n",
    "    for prem_id, file_name in xml_prem_ids_map.items():\n",
    "        if prem_id not in csv_prem_ids:\n",
    "            missing_prem[prem_id] = file_name\n",
    "\n",
    "    for conc_id, file_name in xml_conc_ids_map.items():\n",
    "        if conc_id not in csv_conc_ids:\n",
    "            missing_conc[conc_id] = file_name\n",
    "\n",
    "    print(f\"Missing Premises ({len(missing_prem)}):\")\n",
    "    for pid, fname in missing_prem.items():\n",
    "        print(f\"  Premise ID {pid} from file {fname}\")\n",
    "\n",
    "    print(f\"\\nMissing Conclusions ({len(missing_conc)}):\")\n",
    "    for cid, fname in missing_conc.items():\n",
    "        print(f\"  Conclusion ID {cid} from file {fname}\")\n",
    "\n",
    "    return missing_prem, missing_conc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    xml_folder = 'all_xml_cleaned'\n",
    "    csv_file = 'PC_SA_including_standalone_PC.csv' #change filename for including_standalone\n",
    "    missing_premises, missing_conclusions = find_missing_ids(xml_folder, csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb023cbb",
   "metadata": {},
   "source": [
    "# added no-relation edges in including file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06cf1ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     source_ID                                        source_text target_ID  \\\n",
      "419      E3bis  it states at the outset that its appeal does n...        E1   \n",
      "593         F3  Consequently, the sixth ground of appeal must ...        H4   \n",
      "1616     B7bis  Since it is not notified before it is implemen...        B8   \n",
      "1663       E21  Finally, it must be pointed out that the fact ...       E13   \n",
      "2079       B42  First, it observes that the aim of that measur...       B40   \n",
      "2340    A23bis  secondly, the fact that those exemptions were ...       A25   \n",
      "2342    A25bis  The General Court concluded that, in the parti...        B3   \n",
      "2416    D28bis   \"that assessment is irrelevant to the recover...       C14   \n",
      "\n",
      "                                            target_text     relation  \\\n",
      "419   It should be noted that the third ground of ap...  no-relation   \n",
      "593   However, as the General Court found in paragra...  no-relation   \n",
      "1616  However, the background to the present dispute...  no-relation   \n",
      "1663  Those texts make provision for the Community, ...  no-relation   \n",
      "2079  It follows that the claim that the General Cou...  no-relation   \n",
      "2340  The General Court held that, consequently, Ire...  no-relation   \n",
      "2342  As the General Court observed, in essence, in ...  no-relation   \n",
      "2416  The effectiveness of Article 107 TFEU would be...  no-relation   \n",
      "\n",
      "     source_type target_type  \\\n",
      "419         prem        prem   \n",
      "593         conc        prem   \n",
      "1616        prem        prem   \n",
      "1663        prem        prem   \n",
      "2079        prem        prem   \n",
      "2340        prem        prem   \n",
      "2342        prem        prem   \n",
      "2416        prem        prem   \n",
      "\n",
      "                                              file_name  type_pair  \n",
      "419   R2016_DTS Distribuidora de Televisión Digital.xml  prem-prem  \n",
      "593     R2021_FVE Holýšov I and Others v Commission.xml  prem-conc  \n",
      "1616  R2002_associação dos refinadores de açúcar por...  prem-prem  \n",
      "1663  R2002_associação dos refinadores de açúcar por...  prem-prem  \n",
      "2079  R2021_Prosegur Compañía de Seguridad SA, estab...  prem-prem  \n",
      "2340  A2013_European Commission v Ireland and Others...  prem-prem  \n",
      "2342  A2013_European Commission v Ireland and Others...  prem-prem  \n",
      "2416  A2016_European Commission v Aer Lingus Ltd and...  prem-prem  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "df_including = pd.read_csv('PC_SA_including_standalone_PC.csv')\n",
    "df_without = pd.read_csv('PC_SA_without_standalone_PC.csv')\n",
    "\n",
    "# Perform a merge to find rows in the including file but not in the without file\n",
    "difference = pd.merge(df_including, df_without, how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "\n",
    "# Print the resulting rows\n",
    "print(difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0c844",
   "metadata": {},
   "source": [
    "# Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f70276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Premise Attributes:\n",
      "  ATT\n",
      "  ID\n",
      "  INH\n",
      "  REPH\n",
      "  S\n",
      "  SFF\n",
      "  SUP\n",
      "  T\n",
      "\n",
      "Unique Conclusion Attributes:\n",
      "  ID\n",
      "  SFF\n",
      "  SUP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def extract_unique_attributes(xml_folder):\n",
    "    prem_attrs = set()\n",
    "    conc_attrs = set()\n",
    "\n",
    "    for xml_file in Path(xml_folder).glob(\"*.xml\"):\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            for elem in root.iter():\n",
    "                if elem.tag == 'prem':\n",
    "                    prem_attrs.update(elem.attrib.keys())\n",
    "                elif elem.tag == 'conc':\n",
    "                    conc_attrs.update(elem.attrib.keys())\n",
    "\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"XML parse error in {xml_file.name}: {e}\")\n",
    "\n",
    "    return prem_attrs, conc_attrs\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    folder = 'all_xml'\n",
    "    unique_premise_attributes, unique_conclusion_attributes = extract_unique_attributes(folder)\n",
    "\n",
    "    print(\"Unique Premise Attributes:\")\n",
    "    for attr in sorted(unique_premise_attributes):\n",
    "        print(f\"  {attr}\")\n",
    "\n",
    "    print(\"\\nUnique Conclusion Attributes:\")\n",
    "    for attr in sorted(unique_conclusion_attributes):\n",
    "        print(f\"  {attr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e012d80e",
   "metadata": {},
   "source": [
    "# conclusions never get attacked. premise can attack another premise, conclusion can attack a premise, but a premise never attacks conclusion, also, a conclusion never attacks conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752dd450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d43419c3",
   "metadata": {},
   "source": [
    "### now lets see how many no-relation pairs can be made\n",
    "\n",
    "there are a total of 336 premises and 107 conclusion = 443 total arguments in PC_SA.csv, so there are 443 x 443 = 196249 total relations possible. \n",
    "\n",
    "so, no-relations = total - support - attack = 196249 - 2269 - 145 = 193835 total edges\n",
    "\n",
    "we need to sample from these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de87982",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e6f757",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
