{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca17799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Argumentative       0.58      0.81      0.67       655\n",
      "Non-Argumentative       0.78      0.54      0.64       847\n",
      "\n",
      "         accuracy                           0.66      1502\n",
      "        macro avg       0.68      0.67      0.66      1502\n",
      "     weighted avg       0.69      0.66      0.65      1502\n",
      "\n",
      "Confusion matrix saved to results/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import glob\n",
    "\n",
    "def load_all_predictions(folder_path):\n",
    "    \"\"\"Load all CSV files from the predictions folder and aggregate labels.\"\"\"\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    \n",
    "    all_actual_labels = []\n",
    "    all_predicted_labels = []\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Extract third column (actual_label) and fourth column (predicted_label)\n",
    "        actual_labels = df.iloc[:, 2].tolist()\n",
    "        predicted_labels = df.iloc[:, 3].tolist()\n",
    "        all_actual_labels.extend(actual_labels)\n",
    "        all_predicted_labels.extend(predicted_labels)\n",
    "    \n",
    "    return all_actual_labels, all_predicted_labels\n",
    "\n",
    "def save_classification_report(predictions, labels, output_dir):\n",
    "    \"\"\"Generate and save classification report.\"\"\"\n",
    "    report = classification_report(\n",
    "        labels, predictions,\n",
    "        target_names=[\"Argumentative\", \"Non-Argumentative\"]\n",
    "    )\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(f\"{output_dir}/classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, output_path):\n",
    "    \"\"\"Generate and save confusion matrix plot.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    labels = np.array([\n",
    "        ['(TP)', '(FN)'],\n",
    "        ['(FP)', '(TN)']\n",
    "    ])\n",
    "    \n",
    "    # Create annotation array properly\n",
    "    annot = np.empty_like(labels, dtype=object)\n",
    "    for i in range(labels.shape[0]):\n",
    "        for j in range(labels.shape[1]):\n",
    "            annot[i, j] = f\"{labels[i, j]}\\n{cm[i, j]}\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap=\"Blues\",\n",
    "                xticklabels=[\"Predicted Non-Arg\", \"Predicted Arg\"],\n",
    "                yticklabels=[\"Actual Non-Arg\", \"Actual Arg\"])\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.title('Confusion Matrix for Argumentative Classification')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    folder_path = \"predictions\"\n",
    "    output_dir = \"results\"\n",
    "    \n",
    "    # Load all predictions from CSV files\n",
    "    actual_labels, predicted_labels = load_all_predictions(folder_path)\n",
    "    \n",
    "    # Map labels to match target_names order in classification_report\n",
    "    label_map = {'non-argumentative': 'Non-Argumentative', 'argumentative': 'Argumentative'}\n",
    "    actual_mapped = [label_map[label] for label in actual_labels]\n",
    "    predicted_mapped = [label_map[label] for label in predicted_labels]\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = save_classification_report(predicted_mapped, actual_mapped, output_dir)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    plot_confusion_matrix(actual_mapped, predicted_mapped, f\"{output_dir}/confusion_matrix.png\")\n",
    "    print(f\"Confusion matrix saved to {output_dir}/confusion_matrix.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1fe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
