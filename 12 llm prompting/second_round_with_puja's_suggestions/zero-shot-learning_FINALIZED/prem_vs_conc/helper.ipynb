{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca17799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def save_classification_report(predictions, labels, output_dir):\n",
    "    report = classification_report(\n",
    "        labels, predictions,\n",
    "        target_names=[\"conclusion\", \"premise\"]\n",
    "    )\n",
    "    \n",
    "    with open(f\"{output_dir}/classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, output_path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    labels = np.array([\n",
    "        ['(TP)', '(FN)'],\n",
    "        ['(FP)', '(TN)']\n",
    "    ])\n",
    "    \n",
    "    # Create annotation array properly\n",
    "    annot = np.empty_like(labels, dtype=object)\n",
    "    for i in range(labels.shape[0]):\n",
    "        for j in range(labels.shape[1]):\n",
    "            annot[i, j] = f\"{labels[i, j]}\\n{cm[i, j]}\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap=\"Blues\",\n",
    "                xticklabels=[\"Predicted Conclusion\", \"Predicted Premise\"],\n",
    "                yticklabels=[\"Actual Conclusion\", \"Actual Premise\"])\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.title('Confusion Matrix for Argumentative Classification')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Main processing code\n",
    "folder_path = 'predictions'\n",
    "all_data = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_data.append(df[['actual_class', 'predicted_label']])\n",
    "\n",
    "# Concatenate all data\n",
    "all_data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Map actual classes for consistency\n",
    "all_data_df['actual_class_mapped'] = all_data_df['actual_class'].map({\n",
    "    'prem': 'premise', \n",
    "    'conc': 'conclusion'\n",
    "})\n",
    "\n",
    "# Generate reports\n",
    "output_dir = '.'\n",
    "report = save_classification_report(\n",
    "    all_data_df['predicted_label'], \n",
    "    all_data_df['actual_class_mapped'], \n",
    "    output_dir\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    all_data_df['actual_class_mapped'],\n",
    "    all_data_df['predicted_label'],\n",
    "    \"confusion_matrix.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1fe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
