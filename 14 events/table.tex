\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Fold} & \textbf{Accuracy (Full Text)} & \textbf{Accuracy (Events)} & \textbf{F1 (Full Text)} & \textbf{F1 (Events)} \\
    \hline
    1 & 0.8960 & 0.9641 & 0.7735 & 0.9337 \\
    2 & 0.9864 & 0.9793 & 0.9141 & 0.9351 \\
    3 & 0.9871 & 0.9828 & 0.9087 & 0.9138 \\
    4 & 0.9975 & 0.9795 & 0.9782 & 0.8960 \\
    5 & 0.9932 & 0.9702 & 0.9617 & 0.9132 \\
    6 & 0.9924 & 0.9765 & 0.9231 & 0.8640 \\
    7 & 0.9931 & 0.9979 & 0.9411 & 0.9833 \\
    8 & 0.9981 & 1.0000 & 0.6660 & 1.0000 \\
    9 & 0.9981 & 0.9979 & 0.9518 & 0.9517 \\
    10 & 0.9843 & 0.9757 & 0.9057 & 0.9064 \\
    \hline
    \textbf{Average} & \textbf{0.9826} & \textbf{0.9824} & \textbf{0.8924} & \textbf{0.9297} \\
    \hline
    \end{tabular}
    \caption{Performance comparison of GNN models trained on full text vs. events-only processed embeddings}
    \label{tab:gnn_comparison}
    \end{table}
    