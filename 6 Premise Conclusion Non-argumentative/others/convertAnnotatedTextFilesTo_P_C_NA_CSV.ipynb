{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/suyamoon/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/suyamoon/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "# %% [Cell 2] Import Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Cell 3] Text Reconstruction with Cleaning\n",
    "def reconstruct_and_clean(annotated_path):\n",
    "    \"\"\"Rebuild text with paragraph number removal and position tracking\"\"\"\n",
    "    full_text = []\n",
    "    fragments = []\n",
    "    current_pos = 0\n",
    "    para_pattern = re.compile(r'^\\d+(?:\\.|\\s{2,})\\s*')\n",
    "\n",
    "    with open(annotated_path, 'r', encoding='utf') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Split text and annotation\n",
    "            text_part, _, tag_part = line.partition('||')\n",
    "            text = para_pattern.sub('', text_part.strip())  # Remove paragraph numbers\n",
    "            tag = tag_part.strip()\n",
    "            \n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            # Track positions\n",
    "            start = current_pos\n",
    "            end = start + len(text)\n",
    "            full_text.append(text)\n",
    "            fragments.append({\n",
    "                'text': text,\n",
    "                'tag': tag,\n",
    "                'start': start,\n",
    "                'end': end\n",
    "            })\n",
    "            current_pos = end + 1  # Add space between fragments\n",
    "\n",
    "    return ' '.join(full_text), fragments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECONSTRUCTED TEXT SAMPLE:\n",
      "I  -  11914 JUDGMENT OF 18. 2010 — CASE C-322/09 P JUDGMENT OF THE COURT (Third Chamber) 18 November 2010 * In Case C-322/09 P, APPEAL under Article 56 of the Statute of the Court of Justice, brought on 8 August 2009, NDSHT Nya Destination Stockholm Hotell & Teaterpaket AB, established in Stockholm ...\n",
      "\n",
      "CLEANED FRAGMENTS EXAMPLE:\n",
      "[0000-0011] I  -  11914... | Tag: \n",
      "[0012-0027] JUDGMENT OF 18.... | Tag: NA\n",
      "[0028-0050] 2010 — CASE C-322/09 P... | Tag: \n",
      "[0051-0088] JUDGMENT OF THE COURT (Third Chamber)... | Tag: \n",
      "[0089-0107] 18 November 2010 *... | Tag: \n"
     ]
    }
   ],
   "source": [
    "full_text, fragments = reconstruct_and_clean('annotated/A2010_NDSHT Nya Destination Stockholm Hotell & Teaterpaket AB v European Commission___annotated_judgment.txt')\n",
    "print(\"RECONSTRUCTED TEXT SAMPLE:\")\n",
    "print(full_text[:300] + \"...\\n\")\n",
    "print(\"CLEANED FRAGMENTS EXAMPLE:\")\n",
    "for frag in fragments[:5]:\n",
    "    print(f\"[{frag['start']:04}-{frag['end']:04}] {frag['text'][:50]}... | Tag: {frag['tag']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_sentence_tokenizer(text):\n",
    "    \"\"\"Custom tokenizer for legal text with position tracking\"\"\"\n",
    "    tokenizer = PunktSentenceTokenizer()\n",
    "    sentences = []\n",
    "    char_offset = 0\n",
    "    \n",
    "    for sent in tokenizer.tokenize(text):\n",
    "        # Find sentence boundaries in original text\n",
    "        start = text.find(sent, char_offset)\n",
    "        end = start + len(sent)\n",
    "        \n",
    "        # Legal text adjustments\n",
    "        if sent.endswith(('v.', 'No.', 'Art.', 'para.', 'pp.')):\n",
    "            next_char = text[end:end+1]\n",
    "            if next_char.islower() or next_char.isnumeric():\n",
    "                continue  # Merge abbreviation with next sentence\n",
    "        \n",
    "        sentences.append({\n",
    "            'text': sent,\n",
    "            'start': start,\n",
    "            'end': end\n",
    "        })\n",
    "        char_offset = end\n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOKENIZED SENTENCES:\n",
      "Total sentences: 149\n",
      "Sample sentences:\n",
      "1. [0000-0027] I  -  11914 JUDGMENT OF 18....\n",
      "2. [0028-0596] 2010 — CASE C-322/09 P JUDGMENT OF THE COURT (Third Chamber) 18 November 2010 * ...\n",
      "3. [0597-1421] I  -  11915 NDSHT v COMMISSION THE COURT (Third Chamber), composed of K. Lenaert...\n",
      "4. [1422-1764] 2010 — CASE C-322/09 P NDSHT’s action for annulment of the decision contained in...\n",
      "5. [1765-1964] Legal context 2 As is apparent from recital 2 in its preamble, Council Regulatio...\n",
      "6. [1965-2368] 1), as amended by the Act concerning the conditions of accession of the Czech Re...\n",
      "7. [2369-2537] 33) (‘Regulation No 659/1999’), codifies and reinforces the practice for examini...\n",
      "8. [2538-3143] 3 Under Article  1(b)(i) of that regulation, ‘existing aid’ means ‘without preju...\n",
      "9. [3144-3497] I  -  11917 NDSHT v COMMISSION 4 In accordance with Article 1(h) of that regulat...\n",
      "10. [3498-3637] 5 Article 4(1) to (4) of Regulation No 659/1999, in Chapter II thereof, which is...\n",
      "11. [3639-3711] The Commission shall examine the notification as soon as it is received....\n",
      "12. [3712-3814] Without prejudice to Article 8, the Commission shall take a decision pursuant to...\n",
      "13. [3815-3977] Where the Commission, after a preliminary examination, finds that the notified m...\n",
      "14. [3978-4333] Where the Commission, after a preliminary examination, finds that no doubts are ...\n",
      "15. [4334-4411] The decision shall specify which exception under the Treaty has been applied....\n",
      "16. [4412-4755] Where the Commission, after a preliminary examination, finds that doubts are rai...\n",
      "17. [4756-4857] 2010 — CASE C-322/09 P 6 Chapter III of that regulation governs the procedure re...\n",
      "18. [4858-5271] In that chapter, Article 10(1) provides: ‘Where the Commission has in its posses...\n",
      "19. [5272-5384] …’ 8 In Chapter VI of Regulation No 659/1999, entitled ‘Interested parties’, Art...\n",
      "20. [5386-5491] Any interested party may inform the Commission of any alleged unlawful aid and a...\n",
      "21. [5492-5685] Where the Commission considers that on the basis of the information in its posse...\n",
      "22. [5686-5856] Where the Commission takes a deci sion on a case concerning the subject matter o...\n",
      "23. [5857-6181] At its request, any interested party shall obtain a copy of any decision pursuan...\n",
      "24. [6182-6368] …’ II — Factual background to the dispute 10 NDSHT is a company incorporated und...\n",
      "25. [6369-6593] It offers a packaged service including hotel reservations and a tourist card cal...\n",
      "26. [6594-6706] 11 Stockholm Visitors Board AB (‘SVB’) is a company owned by the City of Stockho...\n",
      "27. [6707-6794] It is responsible for providing tourist information and promoting the Stockholm ...\n",
      "28. [6795-7139] In connection with that type of activity, it also pur sues commercial activities...\n",
      "29. [7140-7388] 12 In September 2004, NDSHT sent the Commission information regarding the an nua...\n",
      "30. [7389-7496] NDSHT asserted in its complaint that that alleged State aid consisted in yearly ...\n",
      "31. [7497-7766] 2010 — CASE C-322/09 P appropriations from the City of Stockholm’s budget in fav...\n",
      "32. [7767-7974] Accord ing to NDSHT, SVB could use that aid to finance its commercial activities...\n",
      "33. [7975-8193] 13 The Commission investigated NDSHT’s complaint in the light of supplementary i...\n",
      "34. [8194-8739] 14 On 24 March 2006, the Director of ‘State Aid 1: Cohesion and Competitiveness’...\n",
      "35. [8740-8957] … I  -  11921 NDSHT v COMMISSION According to our analysis, the Stockholm Card a...\n",
      "36. [8958-9065] These activities are thus not financed from State aid within the meaning of Arti...\n",
      "37. [9066-9332] As regards the use of certain parking spaces for free, arguably there is no affe...\n",
      "38. [9333-9422] Moreover, this service is since 1 Janu ary 2006 no longer included in the Stockh...\n",
      "39. [9423-9499] With respect to other activities (the provision of tourism information, etc....\n",
      "40. [9500-9600] ), it appears as if these are covered by the rules on Services of General Econom...\n",
      "41. [9601-9677] Cross-subsidisation in favour of economic activities does not seem to occur....\n",
      "42. [9678-9886] In case the compensation for the SGEIs would be classified as State aid, such ai...\n",
      "43. [9887-10095] In summary, the extensive investigations we have undertaken on this complaint su...\n",
      "44. [10096-10277] Since there are no grounds to institute the ap propriate measures procedure prov...\n",
      "45. [10278-10308] …’ I  -  11922 JUDGMENT OF 18....\n",
      "46. [10309-10656] 2010 — CASE C-322/09 P 15 By letter of 5 April 2006, NDSHT informed the Commissi...\n",
      "47. [10657-10774] NDSHT also asked the Commission to send it a copy of that decision, in accordanc...\n",
      "48. [10775-11120] 16 By letter of 28 April 2006, the Director of the Commission service responsibl...\n",
      "49. [11121-11401] The proceedings before the General Court and the judgment under appeal 17 By app...\n",
      "50. [11402-11602] 18 By separate document, the Commission raised an objection of inadmissibility p...\n"
     ]
    }
   ],
   "source": [
    "sentences = legal_sentence_tokenizer(full_text)\n",
    "print(\"\\nTOKENIZED SENTENCES:\")\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "print(\"Sample sentences:\")\n",
    "for i, sent in enumerate(sentences[:50]):\n",
    "    print(f\"{i+1}. [{sent['start']:04}-{sent['end']:04}] {sent['text'][:80]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_annotations(sentences, fragments):\n",
    "    dataset = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        class_label = \"NA\"  # Default to non-argumentative\n",
    "        sent_start = sent['start']\n",
    "        sent_end = sent['end']\n",
    "        \n",
    "        for frag in fragments:\n",
    "            # Skip empty tags and NA fragments\n",
    "            if frag['tag'] in ('', 'NA'):\n",
    "                continue\n",
    "                \n",
    "            # Extract argument type (P/C) from tag\n",
    "            tag_type = frag['tag'].split('_')[0]\n",
    "            if tag_type not in ('P', 'C'):\n",
    "                continue\n",
    "\n",
    "            # Calculate overlap\n",
    "            overlap_start = max(sent_start, frag['start'])\n",
    "            overlap_end = min(sent_end, frag['end'])\n",
    "            \n",
    "            if overlap_start < overlap_end:\n",
    "                overlap_ratio = (overlap_end - overlap_start) / (frag['end'] - frag['start'])\n",
    "                if overlap_ratio > 0.6:\n",
    "                    class_label = tag_type  # Set to P/C\n",
    "                    break  # First qualifying fragment determines class\n",
    "        \n",
    "        dataset.append({\n",
    "            'text': sent['text'].strip(),\n",
    "            'class': class_label\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = map_annotations(sentences, fragments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET PREVIEW:\n",
      "Class Distribution:\n",
      "class\n",
      "NA    108\n",
      "P      39\n",
      "C       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Argumentative Sentences:\n",
      "Empty DataFrame\n",
      "Columns: [text, class]\n",
      "Index: []\n",
      "\n",
      "Sample Non-Argumentative Sentences:\n",
      "Empty DataFrame\n",
      "Columns: [text, class]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDATASET PREVIEW:\")\n",
    "print(f\"Class Distribution:\\n{df['class'].value_counts()}\\n\")\n",
    "print(\"Sample Argumentative Sentences:\")\n",
    "print(df[df['class'] == 1].head(3))\n",
    "print(\"\\nSample Non-Argumentative Sentences:\")\n",
    "print(df[df['class'] == 0].head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL DATASET SAMPLE:\n",
      "Class Distribution:\n",
      "class\n",
      "NA    108\n",
      "P      39\n",
      "C       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Premises:\n",
      "                                                 text class  \\\n",
      "97  I  -  11929 NDSHT v COMMISSION Findings of the...     P   \n",
      "98  41 In that regard, it must be observed that it...     P   \n",
      "99  42 However, it is clear that, contrary to the ...     P   \n",
      "\n",
      "                                         cleaned_text  \n",
      "97  I - 11929 NDSHT v COMMISSION Findings of the C...  \n",
      "98  In that regard, it must be observed that it fo...  \n",
      "99  However, it is clear that, contrary to the Com...  \n",
      "\n",
      "Sample Conclusions:\n",
      "                                                  text class  \\\n",
      "102       It follows that that argument is admissible.     C   \n",
      "137  63 In those circumstances, the judgment under ...     C   \n",
      "\n",
      "                                          cleaned_text  \n",
      "102       It follows that that argument is admissible.  \n",
      "137  In those circumstances, the judgment under app...  \n"
     ]
    }
   ],
   "source": [
    "def final_clean(text):\n",
    "    \"\"\"Remove residual noise while preserving legal references\"\"\"\n",
    "    # Remove standalone numbers and bullet points\n",
    "    text = re.sub(r'^\\d+\\.?\\s*', '', text)\n",
    "    # Normalize quotation marks\n",
    "    text = re.sub(r'[”“â€˜â€™]', \"'\", text)\n",
    "    # Fix encoding artifacts\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply final cleaning\n",
    "df['cleaned_text'] = df['text'].apply(final_clean)\n",
    "df = df[df['cleaned_text'].ne('')]\n",
    "\n",
    "# Export to CSV\n",
    "output_path = 'cleaned_legal_dataset.csv'\n",
    "df[['text', 'class']].to_csv(output_path, index=False) \n",
    "\n",
    "print(\"\\nFINAL DATASET SAMPLE:\")\n",
    "print(f\"Class Distribution:\\n{df['class'].value_counts()}\\n\")\n",
    "print(\"Sample Premises:\")\n",
    "print(df[df['class'] == 'P'].head(3))\n",
    "print(\"\\nSample Conclusions:\")\n",
    "print(df[df['class'] == 'C'].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_directory(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('_annotated_judgment.txt'):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            full_text, fragments = reconstruct_and_clean(input_path)\n",
    "            sentences = legal_sentence_tokenizer(full_text)\n",
    "            df = map_annotations(sentences, fragments)\n",
    "            output_path = os.path.join(output_dir, filename.replace('.txt', '.csv'))\n",
    "            df.to_csv(output_path, index=False)\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_directory('annotated', 'P_C_NA csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Cell 1] Add Enhanced Cleaning Functions\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_leading_numbers(text):\n",
    "    \"\"\"Remove 1-3 digit numbers at start of text with trailing period/space\"\"\"\n",
    "    return re.sub(r'^\\d{1,3}\\.*\\s*', '', text).strip()\n",
    "\n",
    "def filter_short_phrases(df):\n",
    "    \"\"\"Remove rows with fewer than 3 words\"\"\"\n",
    "    return df[df['text'].apply(lambda x: len(str(x).split()) >= 3)]\n",
    "\n",
    "# %% [Cell 2] Enhanced Processing Pipeline\n",
    "def enhanced_processing(input_csv, output_csv):\n",
    "    # Load cleaned dataset\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    print(\"Before enhanced cleaning:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    \n",
    "    # Remove leading numbers\n",
    "    df['text'] = df['text'].apply(remove_leading_numbers)\n",
    "    \n",
    "    # Filter short phrases\n",
    "    initial_count = len(df)\n",
    "    df = filter_short_phrases(df)\n",
    "    \n",
    "    # Preserve NA labels explicitly\n",
    "    df['class'] = df['class'].fillna('NA')  # New line to fix missing labels\n",
    "    \n",
    "    print(\"\\nAfter enhanced cleaning:\")\n",
    "    print(f\"Removed {initial_count - len(df)} rows\")\n",
    "    print(f\"Remaining rows: {len(df)}\")\n",
    "    \n",
    "    # Save final dataset\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(input_dir, output_dir):\n",
    "    # Create output directory if not exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Verify input directory exists\n",
    "    if not os.path.exists(input_dir):\n",
    "        raise FileNotFoundError(f\"Input directory '{input_dir}' not found\")\n",
    "    \n",
    "    # Get list of CSV files\n",
    "    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Process each file\n",
    "    for csv_file in csv_files:\n",
    "        input_path = os.path.join(input_dir, csv_file)\n",
    "        output_path = os.path.join(output_dir, csv_file)\n",
    "        \n",
    "        print(f\"Processing {csv_file}...\")\n",
    "        final_df = enhanced_processing(input_path, output_path)\n",
    "        \n",
    "        if final_df is not None:\n",
    "            print(f\"Processed {len(final_df)} rows -> {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R2015_European Commission v MOL Magyar Olaj- és Gázipari Nyrt___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 172\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 2 rows\n",
      "Remaining rows: 170\n",
      "Processed 170 rows -> P_C_NA csv final combined2/R2015_European Commission v MOL Magyar Olaj- és Gázipari Nyrt___annotated_judgment.csv\n",
      "Processing R2000_French Republic v Ladbroke Racing Ltd and Commission of the European Communitie___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 163\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 2 rows\n",
      "Remaining rows: 161\n",
      "Processed 161 rows -> P_C_NA csv final combined2/R2000_French Republic v Ladbroke Racing Ltd and Commission of the European Communitie___annotated_judgment.csv\n",
      "Processing R2004_Ramondín SA and Ramondín Cápsulas SA (C-186_02 P) and Territorio Histórico de Álava - Diputación Foral de Álava (C-188_02 P) v Commission of the European Communities___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 139\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 2 rows\n",
      "Remaining rows: 137\n",
      "Processed 137 rows -> P_C_NA csv final combined2/R2004_Ramondín SA and Ramondín Cápsulas SA (C-186_02 P) and Territorio Histórico de Álava - Diputación Foral de Álava (C-188_02 P) v Commission of the European Communities___annotated_judgment.csv\n",
      "Processing R2016_DTS Distribuidora de Televisión Digital___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 232\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 6 rows\n",
      "Remaining rows: 226\n",
      "Processed 226 rows -> P_C_NA csv final combined2/R2016_DTS Distribuidora de Televisión Digital___annotated_judgment.csv\n",
      "Processing R2011_European Commission v Kronoply GmbH & Co___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 132\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 1 rows\n",
      "Remaining rows: 131\n",
      "Processed 131 rows -> P_C_NA csv final combined2/R2011_European Commission v Kronoply GmbH & Co___annotated_judgment.csv\n",
      "Processing R2006_European Commission v Italian Republic___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 125\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 0 rows\n",
      "Remaining rows: 125\n",
      "Processed 125 rows -> P_C_NA csv final combined2/R2006_European Commission v Italian Republic___annotated_judgment.csv\n",
      "Processing R2002_Associação dos Refinadores de Açúcar Portugueses___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 347\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 6 rows\n",
      "Remaining rows: 341\n",
      "Processed 341 rows -> P_C_NA csv final combined2/R2002_Associação dos Refinadores de Açúcar Portugueses___annotated_judgment.csv\n",
      "Processing R2011_France Télécom SA v European Commission___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 275\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 1 rows\n",
      "Remaining rows: 274\n",
      "Processed 274 rows -> P_C_NA csv final combined2/R2011_France Télécom SA v European Commission___annotated_judgment.csv\n",
      "Processing A2010_NDSHT Nya Destination Stockholm Hotell & Teaterpaket AB v European Commission___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 149\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 1 rows\n",
      "Remaining rows: 148\n",
      "Processed 148 rows -> P_C_NA csv final combined2/A2010_NDSHT Nya Destination Stockholm Hotell & Teaterpaket AB v European Commission___annotated_judgment.csv\n",
      "Processing A2018_Scuola Elementare Maria Montessori Srl v European Commission___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 208\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 1 rows\n",
      "Remaining rows: 207\n",
      "Processed 207 rows -> P_C_NA csv final combined2/A2018_Scuola Elementare Maria Montessori Srl v European Commission___annotated_judgment.csv\n",
      "Processing A2017_Ellinikos Chrysos AE Metalleion kai Viomichanias Chrysou v European Commission___annotated_judgment.csv...\n",
      "Before enhanced cleaning:\n",
      "Total rows: 110\n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 0 rows\n",
      "Remaining rows: 110\n",
      "Processed 110 rows -> P_C_NA csv final combined2/A2017_Ellinikos Chrysos AE Metalleion kai Viomichanias Chrysou v European Commission___annotated_judgment.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the processing\n",
    "process_directory(\n",
    "    'P_C_NA csv',\n",
    "    'P_C_NA csv final combined2'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
