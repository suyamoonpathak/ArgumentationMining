{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb13362",
   "metadata": {},
   "source": [
    "# graph data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc077bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyamoon/miniconda3/lib/python3.12/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/home/suyamoon/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:11: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.3)\n",
      "  from scipy.sparse import csr_matrix, issparse\n",
      "/home/suyamoon/miniconda3/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8c5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = Path(\"filtered_all_removed_conclusion_source.csv\")\n",
    "MODEL_DIR = Path(\"best_model_legalbert_pc\") #suyamoonpathak/legalbert-pcna-finetuned\n",
    "OUTPUT_DIR = Path(\"GAUSSIAN_graph_data_for_joint_prediction_csv\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ef9223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:58:29.648549: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-20 22:58:29.710436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758389309.730146  406523 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758389309.739085  406523 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758389309.765801  406523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758389309.765836  406523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758389309.765839  406523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758389309.765841  406523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-20 22:58:29.770840: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('suyamoonpathak/legalbert-pcna-finetuned')\n",
    "model = AutoModel.from_pretrained('suyamoonpathak/legalbert-pcna-finetuned')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f885954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge type mapping from CSV relations to integers compatible with previous code convention\n",
    "relation_to_edge_type = {\n",
    "    \"support\": 0,\n",
    "    \"attack\": 1,\n",
    "    \"no-relation\": 2\n",
    "}\n",
    "\n",
    "# Node label mapping for node classification\n",
    "node_type_to_label = {\n",
    "    \"premise\": 0,\n",
    "    \"conclusion\": 1,\n",
    "    \"non-argumentative\": 2\n",
    "}\n",
    "\n",
    "# Priority order for node type when a node appears as both source and target with different types\n",
    "node_type_priority = {\n",
    "    \"conclusion\": 3,\n",
    "    \"premise\": 2,\n",
    "    \"non-argumentative\": 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c66deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, batch_size=4):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch,\n",
    "                           padding=True,\n",
    "                           truncation=True,\n",
    "                           max_length=512,\n",
    "                           return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu())\n",
    "    return torch.cat(embeddings, dim=0)\n",
    "\n",
    "def generate_raw_embeddings_from_word_embeddings(texts, batch_size=8):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=512, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        # Extract token IDs from the tokenizer output\n",
    "        input_ids = inputs['input_ids']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get the embeddings directly from the embedding layer\n",
    "            word_embeddings = model.embeddings.word_embeddings(input_ids)\n",
    "            \n",
    "            cls_embeddings = word_embeddings[:, 0, :]  \n",
    "            \n",
    "            embeddings.append(cls_embeddings.cpu())\n",
    "    \n",
    "    return torch.cat(embeddings, dim=0)\n",
    "\n",
    "\n",
    "def generate_gaussian_embeddings(texts, batch_size=4):\n",
    "    hidden_size = model.config.hidden_size\n",
    "    # hidden_size should be set to match model.config.hidden_size\n",
    "    if hidden_size is None:\n",
    "        raise ValueError(\"hidden_size must be specified to match the model's output dimensionality.\")\n",
    "    \n",
    "    embeddings = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_len = len(texts[i:i+batch_size])\n",
    "        # Generate gaussian noise with shape [batch_len, hidden_size]\n",
    "        noise = torch.randn(batch_len, hidden_size).to(device)\n",
    "        embeddings.append(noise.cpu())\n",
    "    \n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ac44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_node_types(source_infos, target_infos):\n",
    "    \"\"\"\n",
    "    Given dictionaries mapping text to set of source_types and target_types,\n",
    "    determine final node type by priority:\n",
    "    conclusion > premise > non-argumentative\n",
    "    \"\"\"\n",
    "    node_types = {}\n",
    "    all_nodes = set(list(source_infos.keys()) + list(target_infos.keys()))\n",
    "    \n",
    "    for text in all_nodes:\n",
    "        source_types = source_infos.get(text, set())\n",
    "        target_types = target_infos.get(text, set())\n",
    "        combined_types = source_types.union(target_types)\n",
    "        \n",
    "        # Pick type by priority order\n",
    "        best_type = None\n",
    "        best_priority = 0\n",
    "        for t in combined_types:\n",
    "            prio = node_type_priority.get(t, 0)\n",
    "            if prio > best_priority:\n",
    "                best_priority = prio\n",
    "                best_type = t\n",
    "        if best_type is None:\n",
    "            # fallback to non-argumentative if something unexpected\n",
    "            best_type = \"non-argumentative\"\n",
    "        node_types[text] = best_type\n",
    "    return node_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16bf9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "file_names = df['file_name'].unique()\n",
    "assert len(file_names) == 40, f\"Expected 40 files, found {len(file_names)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 32902.95it/s]?it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 27460.98it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 30822.34it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 34100.03it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 25906.76it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 23488.92it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 31139.89it/s]00, 55.20it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 31579.29it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 34213.03it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 25500.98it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 29865.98it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 41583.91it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 39585.88it/s]:00, 56.58it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 43287.22it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 39021.69it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 41391.16it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 36393.09it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 30936.71it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 27530.71it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 26922.52it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 28560.44it/s]:00, 63.16it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 27813.69it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 31205.51it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41598.77it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 43255.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 26728.93it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 53483.03it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 19444.33it/s]:00, 63.73it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 33508.21it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 29786.45it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 29489.88it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 37923.18it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 43389.35it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 48753.26it/s]\n",
      "100%|██████████| 28/28 [00:00<00:00, 40054.74it/s]:00, 61.61it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 37012.08it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 46497.70it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 36736.90it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 42027.09it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 34575.75it/s]\n",
      "Processing cases: 100%|██████████| 40/40 [00:00<00:00, 61.49it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for file_name in tqdm(file_names, desc=\"Processing cases\"):\n",
    "    sub_df = df[df['file_name'] == file_name]\n",
    "\n",
    "    # 1. Extract all unique node texts (source and target)\n",
    "    source_texts = sub_df['source_text'].tolist()\n",
    "    target_texts = sub_df['target_text'].tolist()\n",
    "    unique_texts = list(set(source_texts).union(set(target_texts)))\n",
    "\n",
    "    # 2. Collect node types from source_type and target_type\n",
    "    # Map text to set of source_types or target_types (because text can appear multiple times)\n",
    "    source_type_map = {}\n",
    "    target_type_map = {}\n",
    "    for _, row in sub_df.iterrows():\n",
    "        # source\n",
    "        st = row['source_text']\n",
    "        s_type = row['source_type'].strip().lower()\n",
    "        source_type_map.setdefault(st, set()).add(s_type)\n",
    "        # target\n",
    "        tt = row['target_text']\n",
    "        t_type = row['target_type'].strip().lower()\n",
    "        target_type_map.setdefault(tt, set()).add(t_type)\n",
    "\n",
    "    # 3. Determine final node types by priority of presence among source and target types\n",
    "    node_types = determine_node_types(source_type_map, target_type_map)\n",
    "\n",
    "    # 4. Map each unique text to index\n",
    "    text_to_idx = {text: idx for idx, text in enumerate(unique_texts)}\n",
    "\n",
    "    # 5. Generate embeddings for nodes\n",
    "    embeddings = generate_embeddings(unique_texts)\n",
    "\n",
    "    # 6. Create one-hot encoded node type features (3 classes)\n",
    "    node_features_type = torch.zeros((len(unique_texts), 3))\n",
    "    node_labels = []\n",
    "    for i, text in enumerate(unique_texts):\n",
    "        ntype = node_types[text]\n",
    "        label = node_type_to_label.get(ntype, 2)  # Default non-argumentative if missing\n",
    "        node_labels.append(label)\n",
    "        if ntype == \"premise\":\n",
    "            node_features_type[i, 0] = 1\n",
    "        elif ntype == \"conclusion\":\n",
    "            node_features_type[i, 1] = 1\n",
    "        else:\n",
    "            node_features_type[i, 2] = 1\n",
    "\n",
    "    node_labels = torch.tensor(node_labels, dtype=torch.long)\n",
    "    node_features = torch.cat([embeddings, node_features_type], dim=1)\n",
    "\n",
    "    # 7. Build edges - edge indices and edge types\n",
    "    edge_indices = []\n",
    "    edge_types = []\n",
    "    for _, row in sub_df.iterrows():\n",
    "        src_text = row['source_text']\n",
    "        tgt_text = row['target_text']\n",
    "        rel = row['relation'].strip().lower()\n",
    "        if src_text in text_to_idx and tgt_text in text_to_idx:\n",
    "            edge_indices.append([text_to_idx[src_text], text_to_idx[tgt_text]])\n",
    "            edge_types.append(relation_to_edge_type[rel])\n",
    "        else:\n",
    "            print(f\"Warning: Missing node index for edge {src_text} -> {tgt_text} in file {file_name}\")\n",
    "\n",
    "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    edge_type = torch.tensor(edge_types, dtype=torch.long)\n",
    "\n",
    "    # 8. Create Data object\n",
    "    data = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_type=edge_type,\n",
    "        y=node_labels,\n",
    "        xml_file=file_name\n",
    "    )\n",
    "\n",
    "    # 9. Save Data object as .pt file with filename exactly as file_name.pt\n",
    "    output_path = OUTPUT_DIR / f\"{file_name}.pt\"\n",
    "    torch.save(data, output_path)\n",
    "    all_data.append(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0befaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved 40 files.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processed and saved {len(all_data)} files.\")\n",
    "\n",
    "assert len(all_data) == 40, f\"Warning: processed file count mismatch, expected 40 but got {len(all_data)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb383fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
