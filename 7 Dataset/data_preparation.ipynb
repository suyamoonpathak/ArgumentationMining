{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816bb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9338261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_similarity(a, b):\n",
    "    return SequenceMatcher(None, a.strip().lower(), b.strip().lower()).ratio()\n",
    "\n",
    "def parse_annotated_file(annotated_path):\n",
    "    \"\"\"Parse annotated text file into segments\"\"\"\n",
    "    segments = []\n",
    "    with open(annotated_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.split('||')\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            text = parts[0].strip()\n",
    "            label = parts[1].strip()\n",
    "            \n",
    "            if label == 'NA':\n",
    "                segments.append({'text': text, 'type': 'non-argumentative', 'id': None})\n",
    "            elif label.startswith('P_'):\n",
    "                segments.append({'text': text, 'type': 'premise', 'id': label[2:]})\n",
    "            elif label.startswith('C_'):\n",
    "                segments.append({'text': text, 'type': 'conclusion', 'id': label[2:]})\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afa549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_relations(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    relations = []\n",
    "    for elem in tree.iter():\n",
    "        if elem.tag not in ['prem', 'conc']:\n",
    "            continue\n",
    "        source_id = elem.attrib['ID']\n",
    "        for target in elem.attrib.get('SUP', '').split('|'):\n",
    "            if target:\n",
    "                relations.append(('support', source_id, target))\n",
    "        for target in elem.attrib.get('ATT', '').split('|'):\n",
    "            if target:\n",
    "                relations.append(('attack', source_id, target))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9be2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_mapping(segments):\n",
    "    id_map = {}\n",
    "    for seg in segments:\n",
    "        if seg['id'] is None:\n",
    "            continue\n",
    "        existing = id_map.get(seg['id'])\n",
    "        if existing is None or text_similarity(seg['text'], existing['text']) < 0.8:\n",
    "            id_map[seg['id']] = seg\n",
    "    return id_map\n",
    "\n",
    "def process_document(base_name, annotated_folder, xml_folder):\n",
    "    annotated_path = os.path.join(annotated_folder, f\"{base_name}___annotated_judgment.txt\")\n",
    "    if not os.path.exists(annotated_path):\n",
    "        return []\n",
    "    segments = parse_annotated_file(annotated_path)\n",
    "    id_map = create_id_mapping(segments)\n",
    "    xml_path = os.path.join(xml_folder, f\"{base_name}.xml\")\n",
    "    if not os.path.exists(xml_path):\n",
    "        return []\n",
    "    relations = parse_xml_relations(xml_path)\n",
    "    pairs = []\n",
    "    for i, src in enumerate(segments):\n",
    "        for j, tgt in enumerate(segments):\n",
    "            if i == j:\n",
    "                continue\n",
    "            relation = 'no-relation'\n",
    "            if src['type'] != 'non-argumentative' and tgt['type'] != 'non-argumentative':\n",
    "                src_id = src['id']\n",
    "                tgt_id = tgt['id']\n",
    "                for rel_type, s_id, t_id in relations:\n",
    "                    if (text_similarity(src_id, s_id) > 0.8 and \n",
    "                        text_similarity(tgt_id, t_id) > 0.8):\n",
    "                        relation = rel_type\n",
    "                        break\n",
    "            pairs.append({\n",
    "                'source_text': src['text'],\n",
    "                'target_text': tgt['text'],\n",
    "                'relation': relation,\n",
    "                'source_type': src['type'],\n",
    "                'target_type': tgt['type'],\n",
    "                'file_name': base_name\n",
    "            })\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(annotated_folder, xml_folder, output_file):\n",
    "    annotated_files = [f for f in os.listdir(annotated_folder)\n",
    "                       if f.endswith('___annotated_judgment.txt')]\n",
    "    all_pairs = []\n",
    "    for annotated_file in tqdm(annotated_files, desc=f\"Processing {output_file}\"):\n",
    "        base_name = annotated_file.replace('___annotated_judgment.txt', '')\n",
    "        pairs = process_document(base_name, annotated_folder, xml_folder)\n",
    "        all_pairs.extend(pairs)\n",
    "    df = pd.DataFrame(all_pairs)\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(subset=['source_text', 'target_text', 'file_name'])\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Dataset created with {len(df)} pairs. Saved to {output_file}\")\n",
    "    else:\n",
    "        print(f\"No data found for {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b495e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing relations_train.csv: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 1396641 pairs. Saved to relations_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing relations_test.csv: 100%|██████████| 8/8 [00:35<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 297765 pairs. Saved to relations_test.csv\n"
     ]
    }
   ],
   "source": [
    "annotated_train_folder = 'annotated_train'\n",
    "xml_train_folder = 'xml_train'\n",
    "annotated_test_folder = 'annotated_test'\n",
    "xml_test_folder = 'xml_test'\n",
    "\n",
    "# Output files\n",
    "train_output = 'relations_train.csv'\n",
    "test_output = 'relations_test.csv'\n",
    "\n",
    "# Process train and test splits\n",
    "process_split(annotated_train_folder, xml_train_folder, train_output)\n",
    "process_split(annotated_test_folder, xml_test_folder, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aeea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:13<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 1601063 pairs. Saved to final_relations_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# data_folder = './'\n",
    "# output_file = 'final_relations_dataset.csv'\n",
    "\n",
    "# # Get list of annotated files\n",
    "# annotated_files = [f for f in os.listdir(os.path.join(data_folder, 'annotated')) \n",
    "#                     if f.endswith('___annotated_judgment.txt')]\n",
    "\n",
    "# # Process all documents\n",
    "# all_pairs = []\n",
    "# for annotated_file in tqdm(annotated_files):\n",
    "#     base_name = annotated_file.replace('___annotated_judgment.txt', '')\n",
    "#     pairs = process_document(base_name, data_folder)\n",
    "#     all_pairs.extend(pairs)\n",
    "\n",
    "# # Create DataFrame and save\n",
    "# df = pd.DataFrame(all_pairs)\n",
    "# df = df.drop_duplicates(subset=['source_text', 'target_text', 'file_name'])\n",
    "# df.to_csv(output_file, index=False)\n",
    "# print(f\"Dataset created with {len(df)} pairs. Saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd99426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc45c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before enhanced cleaning:\n",
      "Total rows: 1396641\n",
      "Sample rows with numbers:\n",
      "    source_text                       target_text     relation  \\\n",
      "306          5.                   JUDGMENT OF 16.  no-relation   \n",
      "307          5.  * Language of the case: English.  no-relation   \n",
      "\n",
      "           source_type        target_type  \\\n",
      "306  non-argumentative  non-argumentative   \n",
      "307  non-argumentative  non-argumentative   \n",
      "\n",
      "                                             file_name  \n",
      "306  R2002_associacao dos refinadores de acucar por...  \n",
      "307  R2002_associacao dos refinadores de acucar por...  \n",
      "         source_text target_text     relation        source_type  \\\n",
      "0    JUDGMENT OF 16.          5.  no-relation  non-argumentative   \n",
      "299  JUDGMENT OF 16.          1.  no-relation  non-argumentative   \n",
      "300  JUDGMENT OF 16.          2.  no-relation  non-argumentative   \n",
      "\n",
      "           target_type                                          file_name  \n",
      "0    non-argumentative  R2002_associacao dos refinadores de acucar por...  \n",
      "299  non-argumentative  R2002_associacao dos refinadores de acucar por...  \n",
      "300  non-argumentative  R2002_associacao dos refinadores de acucar por...  \n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 472453 rows\n",
      "Remaining rows: 924188\n",
      "Sample cleaned rows:\n",
      "                          source_text  \\\n",
      "614  * Language of the case: English.   \n",
      "615  * Language of the case: English.   \n",
      "616  * Language of the case: English.   \n",
      "\n",
      "                                           target_text     relation  \\\n",
      "614       (hereinafter 'the letter of 19 March 1996').  no-relation   \n",
      "615  [of the common agricultural policy] set out in...  no-relation   \n",
      "616         sugar, and also sugar beet and sugar cane.  no-relation   \n",
      "\n",
      "           source_type        target_type  \\\n",
      "614  non-argumentative  non-argumentative   \n",
      "615  non-argumentative  non-argumentative   \n",
      "616  non-argumentative  non-argumentative   \n",
      "\n",
      "                                             file_name  \n",
      "614  R2002_associacao dos refinadores de acucar por...  \n",
      "615  R2002_associacao dos refinadores de acucar por...  \n",
      "616  R2002_associacao dos refinadores de acucar por...  \n"
     ]
    }
   ],
   "source": [
    "# %% [Cell 1] Add Enhanced Cleaning Functions\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_leading_numbers(text):\n",
    "    \"\"\"Remove 1-3 digit numbers at start of text with trailing period/space\"\"\"\n",
    "    return re.sub(r'^\\d{1,3}\\.*\\s*', '', text).strip()\n",
    "\n",
    "def filter_short_phrases(df):\n",
    "    \"\"\"Remove rows with fewer than 3 words in source_text or target_text\"\"\"\n",
    "    return df[\n",
    "        (df['source_text'].apply(lambda x: len(str(x).split()) >= 4)) &\n",
    "        (df['target_text'].apply(lambda x: len(str(x).split()) >= 4))\n",
    "    ]\n",
    "\n",
    "# %% [Cell 2] Enhanced Processing Pipeline\n",
    "def enhanced_processing(input_csv, output_csv):\n",
    "    # Load cleaned dataset\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    print(\"Before enhanced cleaning:\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(\"Sample rows with numbers:\")\n",
    "    print(df[df['source_text'].str.match(r'^\\d{1,3}\\.')].head(2))\n",
    "    print(df[df['target_text'].str.match(r'^\\d{1,3}\\.')].head(3))\n",
    "\n",
    "        \n",
    "    # Remove leading numbers\n",
    "    df['source_text'] = df['source_text'].apply(remove_leading_numbers)\n",
    "    df['target_text'] = df['target_text'].apply(remove_leading_numbers)\n",
    "        \n",
    "    # Filter short phrases\n",
    "    initial_count = len(df)\n",
    "    df = filter_short_phrases(df)\n",
    "    \n",
    "    print(\"\\nAfter enhanced cleaning:\")\n",
    "    print(f\"Removed {initial_count - len(df)} rows\")\n",
    "    print(f\"Remaining rows: {len(df)}\")\n",
    "    print(\"Sample cleaned rows:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    # Save final dataset\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return df\n",
    "\n",
    "final_df = enhanced_processing('relations_train.csv', 'relations_train_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3345143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before enhanced cleaning:\n",
      "Total rows: 297765\n",
      "Sample rows with numbers:\n",
      "                                        source_text  \\\n",
      "2016  37.5 billion (equivalent to EUR 5.7 billion).   \n",
      "2017  37.5 billion (equivalent to EUR 5.7 billion).   \n",
      "\n",
      "                          target_text     relation        source_type  \\\n",
      "2016                             C.G.  no-relation  non-argumentative   \n",
      "2017  * Language of the case: French.  no-relation  non-argumentative   \n",
      "\n",
      "            target_type                           file_name  \n",
      "2016  non-argumentative  R2016_Orange v European Commission  \n",
      "2017  non-argumentative  R2016_Orange v European Commission  \n",
      "    source_text                                    target_text     relation  \\\n",
      "13         C.G.  37.5 billion (equivalent to EUR 5.7 billion).  no-relation   \n",
      "140        C.G.                                             1.  no-relation   \n",
      "141        C.G.                                             2.  no-relation   \n",
      "\n",
      "           source_type        target_type                           file_name  \n",
      "13   non-argumentative  non-argumentative  R2016_Orange v European Commission  \n",
      "140  non-argumentative  non-argumentative  R2016_Orange v European Commission  \n",
      "141  non-argumentative  non-argumentative  R2016_Orange v European Commission  \n",
      "\n",
      "After enhanced cleaning:\n",
      "Removed 65685 rows\n",
      "Remaining rows: 232080\n",
      "Sample cleaned rows:\n",
      "                         source_text  \\\n",
      "145  * Language of the case: French.   \n",
      "147  * Language of the case: French.   \n",
      "148  * Language of the case: French.   \n",
      "\n",
      "                                           target_text     relation  \\\n",
      "145  By its appeal, Orange seeks to have set aside ...  no-relation   \n",
      "147  The measures covered by the present case are t...  no-relation   \n",
      "148  That scheme, which had been established at the...  no-relation   \n",
      "\n",
      "           source_type        target_type                           file_name  \n",
      "145  non-argumentative  non-argumentative  R2016_Orange v European Commission  \n",
      "147  non-argumentative  non-argumentative  R2016_Orange v European Commission  \n",
      "148  non-argumentative  non-argumentative  R2016_Orange v European Commission  \n"
     ]
    }
   ],
   "source": [
    "final_df_test = enhanced_processing('relations_test.csv', 'relations_test_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcfdda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall relation counts (232080 total pairs):\n",
      "              count\n",
      "no-relation  231510\n",
      "support         507\n",
      "attack           63\n",
      "\n",
      "Per-file relation counts:\n",
      "relation                                            attack  no-relation  \\\n",
      "file_name                                                                 \n",
      "R2016_Hellenic Republic v European Commission            0        13290   \n",
      "R2016_Netherlands Maritime Technology Associati...       8        33237   \n",
      "R2016_Orange v European Commission                       9        19376   \n",
      "R2017_European Commission v Frucona Košice a             0        31096   \n",
      "R2017_Viasat Broadcasting UK Ltd v European Com...       3        14231   \n",
      "R2021_FVE Holýšov I and Others v Commission              7        23219   \n",
      "R2021_Prosegur Compañía de Seguridad SA, establ...      24        55320   \n",
      "R2021_World Duty Free v. Commission                     12        41741   \n",
      "\n",
      "relation                                            support  \n",
      "file_name                                                    \n",
      "R2016_Hellenic Republic v European Commission            51  \n",
      "R2016_Netherlands Maritime Technology Associati...       61  \n",
      "R2016_Orange v European Commission                       75  \n",
      "R2017_European Commission v Frucona Košice a             56  \n",
      "R2017_Viasat Broadcasting UK Ltd v European Com...       46  \n",
      "R2021_FVE Holýšov I and Others v Commission              30  \n",
      "R2021_Prosegur Compañía de Seguridad SA, establ...      118  \n",
      "R2021_World Duty Free v. Commission                      70  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Verify dataset file exists\n",
    "dataset_file = 'relations_test_clean.csv'\n",
    "if not os.path.exists(dataset_file):\n",
    "    print(\"Error: Dataset file not found. Existing files:\")\n",
    "    print('\\n'.join(f for f in os.listdir('.') if f.endswith('.csv')))\n",
    "else:\n",
    "    df = pd.read_csv(dataset_file)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall = df['relation'].value_counts().to_dict()\n",
    "    \n",
    "    # Per-file statistics\n",
    "    per_file = df.groupby('file_name')['relation'].value_counts().unstack(fill_value=0)\n",
    "    \n",
    "    print(f\"\\nOverall relation counts ({len(df)} total pairs):\")\n",
    "    print(pd.DataFrame.from_dict(overall, orient='index', columns=['count']))\n",
    "    \n",
    "    print(\"\\nPer-file relation counts:\")\n",
    "    print(per_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035e6ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall relation counts (924188 total pairs):\n",
      "              count\n",
      "no-relation  922734\n",
      "support        1397\n",
      "attack           57\n",
      "\n",
      "Per-file relation counts:\n",
      "relation                                            attack  no-relation  \\\n",
      "file_name                                                                 \n",
      "A2008_Commission of the European Communities v ...       2        23823   \n",
      "A2009_3F v Commission of the European Communities        4        25699   \n",
      "A2009_Commission of the European Communities v ...       0        16482   \n",
      "A2010_NDSHT Nya Destination Stockholm Hotell & ...       0         9097   \n",
      "A2011_European Commission (C-106_09 P) and King...       2        70994   \n",
      "A2012_BNP Paribas and Banca Nazionale del Lavor...       3        49478   \n",
      "A2013_European Commission v Ireland and Others           0         9266   \n",
      "A2013_Frucona Košice a.s. v European Commission          1        30059   \n",
      "A2016_European Commission v Aer Lingus Ltd and ...       2        40139   \n",
      "A2016_European_Commission_v_World_Duty_Free              1        26013   \n",
      "A2017_Ellinikos Chrysos AE Metalleion kai Viomi...       1         7634   \n",
      "A2017_European Commission v Italian Republic_DT          1        12150   \n",
      "A2017_European Commission v TV2_Danmark A_S              1        14732   \n",
      "A2018_Commission v Spain                                 5        50770   \n",
      "A2018_Dirk Andres v European Commission                  4        22598   \n",
      "A2018_Scuola Elementare Maria Montessori Srl v ...       3        25036   \n",
      "R1997_Tiercé Ladbroke SA v Commission of the Eu...       4         7458   \n",
      "R2000_French Republic v Ladbroke Racing Ltd and...       8        10476   \n",
      "R2002_associacao dos refinadores de acucar port...       2        52613   \n",
      "R2004_Daewoo Electronics Manufacturing España S...       0        20587   \n",
      "R2004_Italian Republic v Commission of the Euro...       0        27697   \n",
      "R2004_Ramondín SA and Ramondín Cápsulas SA (C-1...       0         9489   \n",
      "R2006_European Commission v Italian Republic             1        14723   \n",
      "R2010_AceaElectrabel Produzione SpA v European ...       0       131347   \n",
      "R2011_European Commission v Kronoply GmbH & Co           0         8527   \n",
      "R2011_France Télécom SA v European Commission            0        41357   \n",
      "R2012_European Commission v Électricité de Fran...       5        55406   \n",
      "R2013_3F, formerly Specialarbejderforbundet i D...       1        14977   \n",
      "R2013_Telefónica SA v European Commission                0         8902   \n",
      "R2015_European Commission v MOL Magyar Olaj- és...       0        15224   \n",
      "R2016_DTS Distribuidora de Televisión Digital            6        50307   \n",
      "R2016_European Commission v Hansestadt Lübeck            0        19674   \n",
      "\n",
      "relation                                            support  \n",
      "file_name                                                    \n",
      "A2008_Commission of the European Communities v ...       47  \n",
      "A2009_3F v Commission of the European Communities        59  \n",
      "A2009_Commission of the European Communities v ...       32  \n",
      "A2010_NDSHT Nya Destination Stockholm Hotell & ...       23  \n",
      "A2011_European Commission (C-106_09 P) and King...       30  \n",
      "A2012_BNP Paribas and Banca Nazionale del Lavor...       26  \n",
      "A2013_European Commission v Ireland and Others           46  \n",
      "A2013_Frucona Košice a.s. v European Commission          43  \n",
      "A2016_European Commission v Aer Lingus Ltd and ...       61  \n",
      "A2016_European_Commission_v_World_Duty_Free              70  \n",
      "A2017_Ellinikos Chrysos AE Metalleion kai Viomi...       21  \n",
      "A2017_European Commission v Italian Republic_DT          59  \n",
      "A2017_European Commission v TV2_Danmark A_S              30  \n",
      "A2018_Commission v Spain                                 75  \n",
      "A2018_Dirk Andres v European Commission                  49  \n",
      "A2018_Scuola Elementare Maria Montessori Srl v ...       85  \n",
      "R1997_Tiercé Ladbroke SA v Commission of the Eu...       22  \n",
      "R2000_French Republic v Ladbroke Racing Ltd and...       23  \n",
      "R2002_associacao dos refinadores de acucar port...       58  \n",
      "R2004_Daewoo Electronics Manufacturing España S...       16  \n",
      "R2004_Italian Republic v Commission of the Euro...       25  \n",
      "R2004_Ramondín SA and Ramondín Cápsulas SA (C-1...       18  \n",
      "R2006_European Commission v Italian Republic             38  \n",
      "R2010_AceaElectrabel Produzione SpA v European ...       64  \n",
      "R2011_European Commission v Kronoply GmbH & Co           29  \n",
      "R2011_France Télécom SA v European Commission            56  \n",
      "R2012_European Commission v Électricité de Fran...       52  \n",
      "R2013_3F, formerly Specialarbejderforbundet i D...       29  \n",
      "R2013_Telefónica SA v European Commission                29  \n",
      "R2015_European Commission v MOL Magyar Olaj- és...       29  \n",
      "R2016_DTS Distribuidora de Televisión Digital            87  \n",
      "R2016_European Commission v Hansestadt Lübeck            66  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Verify dataset file exists\n",
    "dataset_file = 'relations_train_clean.csv'\n",
    "if not os.path.exists(dataset_file):\n",
    "    print(\"Error: Dataset file not found. Existing files:\")\n",
    "    print('\\n'.join(f for f in os.listdir('.') if f.endswith('.csv')))\n",
    "else:\n",
    "    df = pd.read_csv(dataset_file)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall = df['relation'].value_counts().to_dict()\n",
    "    \n",
    "    # Per-file statistics\n",
    "    per_file = df.groupby('file_name')['relation'].value_counts().unstack(fill_value=0)\n",
    "    \n",
    "    print(f\"\\nOverall relation counts ({len(df)} total pairs):\")\n",
    "    print(pd.DataFrame.from_dict(overall, orient='index', columns=['count']))\n",
    "    \n",
    "    print(\"\\nPer-file relation counts:\")\n",
    "    print(per_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074d876a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset composition:\n",
      "relation\n",
      "no-relation    2400\n",
      "support        1397\n",
      "attack           57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total samples: 3854\n",
      "Saved to: balanced_relations_train_clean.csv.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2251620/3618991982.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(75, len(x)),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "input_file = \"relations_train_clean.csv\"\n",
    "output_file = \"balanced_relations_train_clean.csv.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Separate relations\n",
    "    support = df[df['relation'] == 'support']\n",
    "    attack = df[df['relation'] == 'attack']\n",
    "    no_relation = df[df['relation'] == 'no-relation']\n",
    "\n",
    "    # Sample 75 no-relation per file\n",
    "    sampled_no_relation = no_relation.groupby('file_name', group_keys=False)\\\n",
    "                                    .apply(lambda x: x.sample(n=min(75, len(x)), \n",
    "                                                             random_state=42))\n",
    "\n",
    "    # Combine all relations\n",
    "    balanced_df = pd.concat([support, attack, sampled_no_relation], ignore_index=True)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Save to new file\n",
    "    balanced_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"Final dataset composition:\")\n",
    "    print(balanced_df['relation'].value_counts())\n",
    "    print(f\"\\nTotal samples: {len(balanced_df)}\")\n",
    "    print(f\"Saved to: {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{input_file}' not found. Please verify:\")\n",
    "    print(\"1. The file exists in the current directory\")\n",
    "    print(\"2. The filename is spelled correctly\")\n",
    "    print(\"3. The file path is correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d67719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset composition:\n",
      "relation\n",
      "no-relation    600\n",
      "support        507\n",
      "attack          63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total samples: 1170\n",
      "Saved to: balanced_relations_test_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2251620/2815416713.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(75, len(x)),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "input_file = \"relations_test_clean.csv\"\n",
    "output_file = \"balanced_relations_test_clean.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Separate relations\n",
    "    support = df[df['relation'] == 'support']\n",
    "    attack = df[df['relation'] == 'attack']\n",
    "    no_relation = df[df['relation'] == 'no-relation']\n",
    "\n",
    "    # Sample 75 no-relation per file\n",
    "    sampled_no_relation = no_relation.groupby('file_name', group_keys=False)\\\n",
    "                                    .apply(lambda x: x.sample(n=min(75, len(x)), \n",
    "                                                             random_state=42))\n",
    "\n",
    "    # Combine all relations\n",
    "    balanced_df = pd.concat([support, attack, sampled_no_relation], ignore_index=True)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Save to new file\n",
    "    balanced_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"Final dataset composition:\")\n",
    "    print(balanced_df['relation'].value_counts())\n",
    "    print(f\"\\nTotal samples: {len(balanced_df)}\")\n",
    "    print(f\"Saved to: {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{input_file}' not found. Please verify:\")\n",
    "    print(\"1. The file exists in the current directory\")\n",
    "    print(\"2. The filename is spelled correctly\")\n",
    "    print(\"3. The file path is correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3042a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4042897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_relations_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Create type pair column\n",
    "        df['type_pair'] = df['source_type'] + '-' + df['target_type']\n",
    "        \n",
    "        # 1. Overall relation counts\n",
    "        relation_counts = df['relation'].value_counts().to_dict()\n",
    "        \n",
    "        # 2. Type pair distribution\n",
    "        type_pair_counts = df['type_pair'].value_counts().to_dict()\n",
    "        \n",
    "        # 3. Relation breakdown per type pair\n",
    "        pair_relations = df.groupby(['type_pair', 'relation']).size().unstack(fill_value=0)\n",
    "        \n",
    "        # 4. Detailed metrics\n",
    "        metrics = {\n",
    "            'premise-premise': {\n",
    "                'support': pair_relations.loc['premise-premise', 'support'] if 'premise-premise' in pair_relations.index else 0,\n",
    "                'attack': pair_relations.loc['premise-premise', 'attack'] if 'premise-premise' in pair_relations.index else 0,\n",
    "                'total': type_pair_counts.get('premise-premise', 0)\n",
    "            },\n",
    "            'premise-conclusion': {\n",
    "                'support': pair_relations.loc['premise-conclusion', 'support'] if 'premise-conclusion' in pair_relations.index else 0,\n",
    "                'attack': pair_relations.loc['premise-conclusion', 'attack'] if 'premise-conclusion' in pair_relations.index else 0,\n",
    "                'total': type_pair_counts.get('premise-conclusion', 0)\n",
    "            },\n",
    "            'conclusion-premise': {\n",
    "                'support': pair_relations.loc['conclusion-premise', 'support'] if 'conclusion-premise' in pair_relations.index else 0,\n",
    "                'attack': pair_relations.loc['conclusion-premise', 'attack'] if 'conclusion-premise' in pair_relations.index else 0,\n",
    "                'total': type_pair_counts.get('conclusion-premise', 0)\n",
    "            },\n",
    "            'conclusion-conclusion': {\n",
    "                'support': pair_relations.loc['conclusion-conclusion', 'support'] if 'conclusion-conclusion' in pair_relations.index else 0,\n",
    "                'attack': pair_relations.loc['conclusion-conclusion', 'attack'] if 'conclusion-conclusion' in pair_relations.index else 0,\n",
    "                'total': type_pair_counts.get('conclusion-conclusion', 0)\n",
    "            },\n",
    "            'non-argumentative-premise': {\n",
    "                'total': type_pair_counts.get('non-argumentative-premise', 0)\n",
    "            },\n",
    "            'non-argumentative-conclusion': {\n",
    "                'total': type_pair_counts.get('non-argumentative-conclusion', 0)\n",
    "            },\n",
    "            'premise-non-argumentative': {\n",
    "                'total': type_pair_counts.get('premise-non-argumentative', 0)\n",
    "            },\n",
    "            'conclusion-non-argumentative': {\n",
    "                'total': type_pair_counts.get('conclusion-non-argumentative', 0)\n",
    "            },\n",
    "            'non-argumentative-non-argumentative': {\n",
    "                'total': type_pair_counts.get('non-argumentative-non-argumentative', 0)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_pairs = len(df)\n",
    "        for pair in metrics:\n",
    "            if 'total' in metrics[pair]:\n",
    "                metrics[pair]['percentage'] = (metrics[pair]['total'] / total_pairs) * 100\n",
    "        \n",
    "        return {\n",
    "            'total_pairs': total_pairs,\n",
    "            'relation_distribution': relation_counts,\n",
    "            'type_pair_metrics': metrics,\n",
    "            'detailed_breakdown': pair_relations.to_dict()\n",
    "        }\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        print(\"Please verify:\")\n",
    "        print(\"1. The file exists in the current directory\")\n",
    "        print(\"2. You're using the correct filename (case-sensitive)\")\n",
    "        print(\"3. The file path is correct\")\n",
    "        return None\n",
    "\n",
    "# Run analysis\n",
    "results = analyze_relations_dataset('balanced_relations_test_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc0a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = analyze_relations_dataset('balanced_relations_train_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f71e7ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Pairs: 1170\n",
      "\n",
      "Relation Distribution:\n",
      "             Count\n",
      "no-relation    600\n",
      "support        507\n",
      "attack          63\n",
      "\n",
      "Type Pair Metrics:\n",
      "                                     support  attack  total  percentage\n",
      "premise-premise                        392.0    54.0  563.0   48.119658\n",
      "premise-conclusion                       0.0     9.0   18.0    1.538462\n",
      "conclusion-premise                     115.0     0.0  123.0   10.512821\n",
      "conclusion-conclusion                    0.0     0.0    0.0    0.000000\n",
      "non-argumentative-premise                NaN     NaN  120.0   10.256410\n",
      "non-argumentative-conclusion             NaN     NaN   15.0    1.282051\n",
      "premise-non-argumentative                NaN     NaN  133.0   11.367521\n",
      "conclusion-non-argumentative             NaN     NaN    9.0    0.769231\n",
      "non-argumentative-non-argumentative      NaN     NaN  189.0   16.153846\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    print(\"\\nTotal Pairs:\", results['total_pairs'])\n",
    "    print(\"\\nRelation Distribution:\")\n",
    "    print(pd.DataFrame.from_dict(results['relation_distribution'], orient='index', columns=['Count']))\n",
    "    \n",
    "    print(\"\\nType Pair Metrics:\")\n",
    "    print(pd.DataFrame(results['type_pair_metrics']).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ccc9633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Pairs: 3854\n",
      "\n",
      "Relation Distribution:\n",
      "             Count\n",
      "no-relation   2400\n",
      "support       1397\n",
      "attack          57\n",
      "\n",
      "Type Pair Metrics:\n",
      "                                     support  attack   total  percentage\n",
      "premise-premise                       1176.0    52.0  1516.0   39.335755\n",
      "premise-conclusion                       0.0     5.0    23.0    0.596783\n",
      "conclusion-premise                     221.0     0.0   237.0    6.149455\n",
      "conclusion-conclusion                    0.0     0.0     1.0    0.025947\n",
      "non-argumentative-premise                NaN     NaN   491.0   12.740010\n",
      "non-argumentative-conclusion             NaN     NaN    28.0    0.726518\n",
      "premise-non-argumentative                NaN     NaN   486.0   12.610275\n",
      "conclusion-non-argumentative             NaN     NaN    29.0    0.752465\n",
      "non-argumentative-non-argumentative      NaN     NaN  1043.0   27.062792\n"
     ]
    }
   ],
   "source": [
    "if results_train:\n",
    "    print(\"\\nTotal Pairs:\", results_train['total_pairs'])\n",
    "    print(\"\\nRelation Distribution:\")\n",
    "    print(pd.DataFrame.from_dict(results_train['relation_distribution'], orient='index', columns=['Count']))\n",
    "    \n",
    "    print(\"\\nType Pair Metrics:\")\n",
    "    print(pd.DataFrame(results_train['type_pair_metrics']).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854e38ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as: filtered_relations_train_clean_removed_conclusion_source.csv\n",
      "File saved as: filtered_relations_test_clean_removed_conclusion_source.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_conclusion_premise_rows(input_file, output_file):\n",
    "    try:\n",
    "        # Read the input CSV file\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Create the type pair column\n",
    "        df['type_pair'] = df['source_type'] + '-' + df['target_type']\n",
    "        \n",
    "        # Filter out rows where the type_pair is 'conclusion-premise'\n",
    "        filtered_df = df[df['type_pair'] != 'conclusion-premise']\n",
    "        \n",
    "        # Save the filtered data to a new file\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "        print(f\"File saved as: {output_file}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{input_file}' not found.\")\n",
    "        print(\"Please verify:\")\n",
    "        print(\"1. The file exists in the current directory\")\n",
    "        print(\"2. You're using the correct filename (case-sensitive)\")\n",
    "        print(\"3. The file path is correct\")\n",
    "        \n",
    "# Apply the function to train and test files\n",
    "remove_conclusion_premise_rows('balanced_relations_train_clean.csv', 'filtered_relations_train_clean_removed_conclusion_source.csv')\n",
    "remove_conclusion_premise_rows('balanced_relations_test_clean.csv', 'filtered_relations_test_clean_removed_conclusion_source.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f4844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
