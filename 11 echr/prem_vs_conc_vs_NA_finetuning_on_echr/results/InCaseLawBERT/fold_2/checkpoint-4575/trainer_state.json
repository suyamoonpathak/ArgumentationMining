{
  "best_metric": 0.5872013372053044,
  "best_model_checkpoint": "/DATA9/suyamoon/ArgumentationMining/11 echr/prem_vs_conc_vs_NA/results/InCaseLawBERT/fold_2/checkpoint-3050",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4575,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.7739911675453186,
      "learning_rate": 4.836065573770492e-05,
      "loss": 3.4475,
      "step": 500
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 121.96035766601562,
      "learning_rate": 4.672131147540984e-05,
      "loss": 3.0295,
      "step": 1000
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 9.837760925292969,
      "learning_rate": 4.508196721311476e-05,
      "loss": 3.1498,
      "step": 1500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7728613569321534,
      "eval_f1": 0.5278112499729034,
      "eval_loss": 2.9976959228515625,
      "eval_runtime": 5.632,
      "eval_samples_per_second": 120.383,
      "eval_steps_per_second": 30.185,
      "step": 1525
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 45.10881423950195,
      "learning_rate": 4.3442622950819674e-05,
      "loss": 2.9197,
      "step": 2000
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 59.82101821899414,
      "learning_rate": 4.1803278688524595e-05,
      "loss": 2.9162,
      "step": 2500
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 66.54415893554688,
      "learning_rate": 4.016393442622951e-05,
      "loss": 2.8336,
      "step": 3000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7168141592920354,
      "eval_f1": 0.5872013372053044,
      "eval_loss": 2.614762544631958,
      "eval_runtime": 5.6205,
      "eval_samples_per_second": 120.629,
      "eval_steps_per_second": 30.246,
      "step": 3050
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 2.578030586242676,
      "learning_rate": 3.8524590163934424e-05,
      "loss": 2.8517,
      "step": 3500
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 45.260154724121094,
      "learning_rate": 3.6885245901639346e-05,
      "loss": 2.8068,
      "step": 4000
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 120.94195556640625,
      "learning_rate": 3.524590163934427e-05,
      "loss": 2.6839,
      "step": 4500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7300884955752213,
      "eval_f1": 0.5670590396994084,
      "eval_loss": 3.331035614013672,
      "eval_runtime": 5.6147,
      "eval_samples_per_second": 120.755,
      "eval_steps_per_second": 30.278,
      "step": 4575
    }
  ],
  "logging_steps": 500,
  "max_steps": 15250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4814975544422400.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
